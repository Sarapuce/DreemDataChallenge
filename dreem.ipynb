{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = h5py.File(\"./data/X_train.h5\", \"r\")\n",
    "x_train = df_train[\"features\"][:183143]\n",
    "x_test  = df_train[\"features\"][183143:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"./data/y_train.csv\").values[:183143, 1].squeeze()\n",
    "y_test = pd.read_csv(\"./data/y_train.csv\").values[183143:, 1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/train.npy')\n",
    "x_eval = np.load('./data/test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = data[:183143], data[183143:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waves(x_train):\n",
    "    freq  = 125*np.fft.fftfreq(x_train.shape[1])\n",
    "    eeg   = np.abs(np.fft.fft(x_train))\n",
    "    delta = np.sum(eeg[:, (freq > 0.5) & (freq <= 4)], axis = 1)\n",
    "    theta = np.sum(eeg[:, (freq > 4) & (freq <= 7)], axis = 1)\n",
    "    alpha = np.sum(eeg[:, (freq > 7) & (freq <= 13)], axis = 1)\n",
    "    beta  = np.sum(eeg[:, (freq > 13) & (freq <= 30)], axis = 1)\n",
    "    gamma = np.sum(eeg[:, (freq > 30)], axis = 1)\n",
    "    return np.array([delta, theta, alpha, beta, gamma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(y_train).long()\n",
    "y_test  = torch.tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilisateur\\.conda\\envs\\keelab\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Utilisateur\\.conda\\envs\\keelab\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x_train = torch.tensor(x_train).float()\n",
    "x_test  = torch.tensor(x_test).float()\n",
    "x_eval  = torch.tensor(x_eval).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean  = x_test.mean(dim = 0 ,keepdim=True)\n",
    "test_std   = x_test.std(dim = 0 ,keepdim=True)\n",
    "train_mean = x_train.mean(dim = 0 ,keepdim=True)\n",
    "train_std  = x_train.std(dim = 0 ,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mean = x_eval.mean(dim = 0 ,keepdim=True)\n",
    "eval_std = x_eval.std(dim = 0 ,keepdim=True)\n",
    "x_eval  = (x_eval - eval_mean) / eval_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test  = (x_test - test_mean) / test_std\n",
    "x_train = (x_train - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = utils.TensorDataset(x_train, y_train)\n",
    "test_data  = utils.TensorDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = utils.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader  = utils.DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.do1 = nn.Dropout(p = 0.3)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.do2 = nn.Dropout(p = 0.25)\n",
    "        self.fc4 = nn.Linear(16, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.do1(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.do2(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c86b06811b4742af9d9998a62aab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 1.000247526676983\n",
      "Epoch 1 - Training loss: 0.991282894259812\n",
      "Epoch 2 - Training loss: 0.9898961142882194\n",
      "Epoch 3 - Training loss: 0.9887845430817328\n",
      "Epoch 4 - Training loss: 0.9879042007013437\n",
      "Epoch 5 - Training loss: 0.9875378128867479\n",
      "Epoch 6 - Training loss: 0.9871817643329199\n",
      "Epoch 7 - Training loss: 0.9870561729312193\n",
      "Epoch 8 - Training loss: 0.9867503568686279\n",
      "Epoch 9 - Training loss: 0.9861671906472252\n",
      "Epoch 10 - Training loss: 0.9856953277694521\n",
      "Epoch 11 - Training loss: 0.9851156873856284\n",
      "Epoch 12 - Training loss: 0.9854971408677384\n",
      "Epoch 13 - Training loss: 0.9846565163610367\n",
      "Epoch 14 - Training loss: 0.9851601572823141\n",
      "Epoch 15 - Training loss: 0.984463913094156\n",
      "Epoch 16 - Training loss: 0.9841398324981425\n",
      "Epoch 17 - Training loss: 0.984217988786624\n",
      "Epoch 18 - Training loss: 0.9842312471338455\n",
      "Epoch 19 - Training loss: 0.9837566175550785\n",
      "Epoch 20 - Training loss: 0.9839033638989484\n",
      "Epoch 21 - Training loss: 0.9838327181705805\n",
      "Epoch 22 - Training loss: 0.9831766097758884\n",
      "Epoch 23 - Training loss: 0.9832717468695238\n",
      "Epoch 24 - Training loss: 0.982826035831626\n",
      "Epoch 25 - Training loss: 0.9825010767647805\n",
      "Epoch 26 - Training loss: 0.9829313579053832\n",
      "Epoch 27 - Training loss: 0.9823102688222894\n",
      "Epoch 28 - Training loss: 0.9822715609786729\n",
      "Epoch 29 - Training loss: 0.9821159836714456\n",
      "Epoch 30 - Training loss: 0.9825459960913175\n",
      "Epoch 31 - Training loss: 0.9823466149099551\n",
      "Epoch 32 - Training loss: 0.9817436932476145\n",
      "Epoch 33 - Training loss: 0.9822934432349615\n",
      "Epoch 34 - Training loss: 0.981565400468645\n",
      "Epoch 35 - Training loss: 0.9811533708450763\n",
      "Epoch 36 - Training loss: 0.9813854803079329\n",
      "Epoch 37 - Training loss: 0.9802506253237827\n",
      "Epoch 38 - Training loss: 0.9807892475904575\n",
      "Epoch 39 - Training loss: 0.9803545061813878\n",
      "Epoch 40 - Training loss: 0.9804699240573881\n",
      "Epoch 41 - Training loss: 0.980493318463938\n",
      "Epoch 42 - Training loss: 0.9804083091616214\n",
      "Epoch 43 - Training loss: 0.9804728214845717\n",
      "Epoch 44 - Training loss: 0.9798841991889402\n",
      "Epoch 45 - Training loss: 0.9800751576425311\n",
      "Epoch 46 - Training loss: 0.9793309213646969\n",
      "Epoch 47 - Training loss: 0.9796152982072011\n",
      "Epoch 48 - Training loss: 0.9793761479612999\n",
      "Epoch 49 - Training loss: 0.9795508503830574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for e in tqdm(range(epochs)):\n",
    "    running_loss = 0\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'First')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.exp(model(x_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_pred.detach().numpy(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5114726529156209"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5131034131301678"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (do1): Dropout(p=0.3)\n",
       "  (fc3): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (do2): Dropout(p=0.25)\n",
       "  (fc4): Linear(in_features=16, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['id'] = range(len(test))\n",
    "df['label'] = test\n",
    "df.to_csv('./data/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
